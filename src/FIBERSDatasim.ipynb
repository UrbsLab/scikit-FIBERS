{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c43e875b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from skfibers.fibers import FIBERS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f1314bad",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4231f905",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_features(row, number_of_features, number_of_features_in_bin, mm_frequency):\n",
    "    if row['Class'] == 1:\n",
    "        idxs = random.sample(list(range(1, number_of_features_in_bin + 1)), \n",
    "                             int(mm_frequency/2 * number_of_features_in_bin))\n",
    "        for idx in idxs:\n",
    "            row['P_' + str(idx)] = 1\n",
    "        idxs = random.sample(list(range(1, number_of_features - number_of_features_in_bin + 1)), \n",
    "                             int(mm_frequency/2 * (number_of_features - number_of_features_in_bin)))\n",
    "        for idx in idxs:\n",
    "            row['R_' + str(idx)] = 1\n",
    "    else:\n",
    "        idxs = random.sample(list(range(1, number_of_features - number_of_features_in_bin + 1)), \n",
    "                             int(mm_frequency * (number_of_features - number_of_features_in_bin)))\n",
    "        for idx in idxs:\n",
    "            row['R_' + str(idx)] = 1\n",
    "    return row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ff62a5b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_data_simulation_bin(number_of_instances, number_of_features, number_of_features_in_bin,\n",
    "                               no_fail_proportion, mm_frequency_range, noise_frequency,\n",
    "                               class0_time_to_event_range, class1_time_to_event_range):\n",
    "    \"\"\"\n",
    "    Defining a function to create an artificial dataset with parameters, there will be one ideal/strong bin\n",
    "    Note: MAF (minor allele frequency) cutoff refers to the threshold\n",
    "    separating rare variant features from common features\n",
    "\n",
    "    :param number_of_instances: dataset size\n",
    "    :param number_of_features: total number of features in dataset\n",
    "    :param number_of_features_in_bin: total number of predictive features in the ideal bin\n",
    "    :param no_fail_proportion: the proportion of instances to be labled as (no fail class)\n",
    "    :param mm_frequency_range: the max and min MM frequency for a given column/feature in data. (e.g. 0.1 to 0.5)\n",
    "    :param noise_frequency: Value from 0 to 0.5 representing the proportion of class 0/class 1 instance pairs that \\\n",
    "                            have their outcome switched from 0 to 1\n",
    "    :param class0_time_to_event_range: (min, max) time to event as a tuple (should be larger (e.g. 100 to 200)\n",
    "    :param class1_time_to_event_range: (min, max) time to event as a tuple (should be smaller but a but overlapping \\\n",
    "                                        with above range (e.g. 20 to 150)\n",
    "\n",
    "    :return: pandas dataframe of generated data\n",
    "    \"\"\"\n",
    "    \n",
    "    # Creating an empty dataframe to use as a starting point for the eventual feature matrix\n",
    "    # Adding one to number of features to give space for the class and Duration column\n",
    "    df = pd.DataFrame(np.zeros((number_of_instances, number_of_features + 2)))\n",
    "    \n",
    "    # Creating a list of predictive features in the strong bin\n",
    "    predictive_features = [\"P_\" + str(i + 1) for i in range(number_of_features_in_bin)]\n",
    "\n",
    "    # Creating a list of randomly created features\n",
    "    random_features = [\"R_\" + str(i + 1) for i in range(number_of_features - number_of_features_in_bin)]\n",
    "\n",
    "    # Adding the features and the class/endpoint\n",
    "    df.columns  = predictive_features + random_features + ['Class', 'Duration']\n",
    "    \n",
    "    # Assigning class according to no_fail_proportion parameter\n",
    "    fail_count = int(number_of_instances * (1 - no_fail_proportion))\n",
    "    no_fail_count = number_of_instances - fail_count\n",
    "    class_list = [1] * fail_count + [0] * no_fail_count\n",
    "    df['Class'] = class_list\n",
    "    \n",
    "    # Generating predictive and random features columns\n",
    "    mm_frequency = np.random.uniform(mm_frequency_range[0], mm_frequency_range[1])\n",
    "    df = df.apply(generate_features, \n",
    "                  args=(number_of_features, number_of_features_in_bin, mm_frequency), axis=1).astype(int)\n",
    "    \n",
    "    # Assigning Guassians according to class\n",
    "    df_0 = df[df['Class'] == 0].sample(frac=1).reset_index(drop=True)\n",
    "    df_1 = df[df['Class'] == 1].sample(frac=1).reset_index(drop=True)\n",
    "    df_0['Duration'] = np.random.uniform(class0_time_to_event_range[0], \n",
    "                                         class0_time_to_event_range[1], size=len(df_0))\n",
    "    df_1['Duration'] = np.random.uniform(class1_time_to_event_range[0], \n",
    "                                         class1_time_to_event_range[1], size=len(df_1))\n",
    "    \n",
    "    if noise_frequency > 0:\n",
    "        swap_count = min(no_fail_count, fail_count) * noise_frequency\n",
    "        idxs = random.sample(list(range(min(no_fail_count, fail_count))), swap_count)\n",
    "        for i in idxs:\n",
    "            df_0['Class'].iloc[i], df_1['Class'].iloc[x-1:] = \\\n",
    "            df_1['Class'].iloc[i:].copy(), df_0['Class'].iloc[i:].copy()\n",
    "            df_0['Duration'].iloc[i], df_1['Duration'].iloc[x-1:] = \\\n",
    "            df_1['Duration'].iloc[i:].copy(), df_0['Duration'].iloc[i:].copy()\n",
    "    \n",
    "    df = pd.concat([df_0, df_1]).sample(frac=1).reset_index(drop=True)\n",
    "    \n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d01f5d8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = create_data_simulation_bin(number_of_instances=10000, number_of_features=50, number_of_features_in_bin=10,\n",
    "                                  no_fail_proportion=0.5, mm_frequency_range=(0.4, 0.5) , noise_frequency=0,\n",
    "                                  class0_time_to_event_range=(1.00, 2.00), class1_time_to_event_range=(0.2, 1.50))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7283facc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>P_1</th>\n",
       "      <th>P_2</th>\n",
       "      <th>P_3</th>\n",
       "      <th>P_4</th>\n",
       "      <th>P_5</th>\n",
       "      <th>P_6</th>\n",
       "      <th>P_7</th>\n",
       "      <th>P_8</th>\n",
       "      <th>P_9</th>\n",
       "      <th>P_10</th>\n",
       "      <th>...</th>\n",
       "      <th>R_33</th>\n",
       "      <th>R_34</th>\n",
       "      <th>R_35</th>\n",
       "      <th>R_36</th>\n",
       "      <th>R_37</th>\n",
       "      <th>R_38</th>\n",
       "      <th>R_39</th>\n",
       "      <th>R_40</th>\n",
       "      <th>Class</th>\n",
       "      <th>Duration</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1.046692</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.539363</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.888321</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.243211</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1.809008</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 52 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   P_1  P_2  P_3  P_4  P_5  P_6  P_7  P_8  P_9  P_10  ...  R_33  R_34  R_35  \\\n",
       "0    0    0    0    0    0    0    0    0    0     0  ...     1     1     1   \n",
       "1    0    1    0    0    1    0    0    0    0     0  ...     0     0     1   \n",
       "2    0    0    0    0    0    0    0    0    0     0  ...     0     1     0   \n",
       "3    0    0    0    0    0    0    0    0    0     0  ...     0     1     0   \n",
       "4    0    0    0    0    0    0    0    0    0     0  ...     1     0     1   \n",
       "\n",
       "   R_36  R_37  R_38  R_39  R_40  Class  Duration  \n",
       "0     0     0     0     0     1      0  1.046692  \n",
       "1     0     1     0     0     1      1  0.539363  \n",
       "2     0     0     1     0     0      0  1.888321  \n",
       "3     1     1     1     1     0      0  1.243211  \n",
       "4     0     1     1     1     1      0  1.809008  \n",
       "\n",
       "[5 rows x 52 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "186095b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.to_csv('data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e6dd99da",
   "metadata": {},
   "outputs": [],
   "source": [
    "def experiment_1():\n",
    "    for replicate in range(0, 1):\n",
    "        print('Experiment 1')\n",
    "        # Creating the simulated dataset with 1000 instances, 10 features to bin, 50 total features\n",
    "        # no_fail_proportion=0.5, mm_frequency_range=(0.1, 0.5) , noise_frequency=0,\n",
    "        # class0_time_to_event_range=(100, 200), class1_time_to_event_range=(20, 150)\n",
    "        data = create_data_simulation_bin(1000, 50, 10, 0.5, (0.1, 0.5), 0, (100, 200), (20, 150))\n",
    "\n",
    "        fibers = FIBERS(given_starting_point=False, amino_acid_start_point=None, algorithm=\"FIBERS\",\n",
    "                        amino_acid_bins_start_point=None, iterations=500, label_name=\"Class\",\n",
    "                        duration_name=\"Duration\", rare_variant_maf_cutoff=0.05,\n",
    "                        set_number_of_bins=50, min_features_per_group=5,\n",
    "                        max_number_of_groups_with_feature=25,\n",
    "                        scoring_method='Relief',\n",
    "                        score_based_on_sample=True, score_with_common_variables=False,\n",
    "                        instance_sample_size=50, crossover_probability=0.8,\n",
    "                        mutation_probability=0.1, elitism_parameter=0.4,\n",
    "                        random_seed=None, bin_size_variability_constraint=None)\n",
    "\n",
    "        fibers.fit(data)\n",
    "        fibers, bin_feature_matrix_internal, amino_acid_bins_internal, \\\n",
    "            amino_acid_bin_scores_internal, maf_0_features = fibers.transform(data)\n",
    "        print(amino_acid_bins_internal)\n",
    "        print(amino_acid_bin_scores_internal)\n",
    "        print(maf_0_features)\n",
    "        return bin_feature_matrix_internal, amino_acid_bins_internal, \\\n",
    "            amino_acid_bin_scores_internal, maf_0_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c67474c8",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Experiment 1\n",
      "FIBERS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|▎                                          | 3/500 [00:09<26:54,  3.25s/it]"
     ]
    }
   ],
   "source": [
    "bin_feature_matrix_internal, amino_acid_bins_internal, \\\n",
    "            amino_acid_bin_scores_internal, maf_0_features = experiment_1()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc3f1622",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(amino_acid_bins_internal)\n",
    "print(amino_acid_bin_scores_internal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "589a9638",
   "metadata": {},
   "outputs": [],
   "source": [
    "from skfibers.methods.fibers_methods import top_bin_summary_fibers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "936467e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "top_bin_summary_fibers(pd.DataFrame(), \"Class\", \"Duration\", bin_feature_matrix_internal, amino_acid_bins_internal,\n",
    "                       amino_acid_bin_scores_internal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "155c2400",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:development]",
   "language": "python",
   "name": "conda-env-development-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
