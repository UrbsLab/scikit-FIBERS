{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fb202e16",
   "metadata": {},
   "source": [
    "# New scikit-FIBERS Run"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "933a1eea",
   "metadata": {},
   "source": [
    "## Installation and Imports \n",
    "How to setup and use scikit-FIBERS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4796d42d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import copy\n",
    "import dask\n",
    "import pickle\n",
    "import pandas as pd\n",
    "from lifelines import CoxPHFitter\n",
    "from src.skfibers import FIBERS\n",
    "from src.skfibers.methods.data_handling import prepare_data\n",
    "from sklearn.metrics import accuracy_score\n",
    "from dask.distributed import Client\n",
    "from dask_jobqueue import SLURMCluster, LSFCluster, SGECluster"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2faeffa9",
   "metadata": {},
   "source": [
    "## Loading dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "887ae0d4",
   "metadata": {},
   "source": [
    "### Setting Variables for General Experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "54445d43",
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataset_name_list = os.listdir('PPSNDatasets')\n",
    "dataset_name_list = [   'standard_with_noise.csv',\n",
    "                        'standard_no_noise.csv',\n",
    "                        'threshold_0_no_noise.csv',\n",
    "                        'threshold_0_with_noise.csv',\n",
    "                        'threshold_1_no_noise.csv',\n",
    "                        'threshold_1_with_noise.csv',\n",
    "                        'threshold_2_no_noise.csv',\n",
    "                        'threshold_2_with_noise.csv',\n",
    "                        'threshold_4_no_noise.csv',\n",
    "                        'threshold_4_with_noise.csv',]\n",
    "experiment_list = ['Goal1', 'Goal2', 'Goal3', 'Goal4', 'Goal5', 'Testing']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "09e1e931",
   "metadata": {},
   "outputs": [],
   "source": [
    "root_folder = 'PPSNResults/FIBERS2/'\n",
    "dataset_name = dataset_name_list[0]\n",
    "experiment_name = experiment_list[4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9aa178fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for experiment_name in experiment_list:\n",
    "#     for dataset_name in dataset_name_list:\n",
    "#         try:\n",
    "#             folder = root_folder + '/' + experiment_name + '/' + dataset_name.split('.')[0] + '/'\n",
    "#             os.makedirs(folder)\n",
    "#         except FileExistsError:\n",
    "#             folder = root_folder + '/' + experiment_name + '/' + dataset_name.split('.')[0] + '/'\n",
    "#             print(\"Folder Already Exists:\" + folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2f0f1be2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_dataset(dataset_name):\n",
    "    data = pd.read_csv('PPSNDatasets/'+ dataset_name)\n",
    "    true_risk_group = data[['TrueRiskGroup']]\n",
    "    data = data.drop('TrueRiskGroup', axis=1)\n",
    "    return data, true_risk_group"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "70b86bfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# data, true_risk_group = read_dataset(dataset_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22c67a18",
   "metadata": {},
   "source": [
    "## Code For Single FIBERS Run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "785104e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pop Size = 50, Iterations = 100, crossover_prob = 0.5, min mutation = 0.1, \n",
    "# elitism = 0.1, min_bin_size = 1, max initial bin size = 10, group_strata_min = 0.2."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8eaca34c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# min mutation = 0.1 and max mutation prob =0.1 (effectively turning off oscillating mutation rate),\n",
    "#  and merge prob = 0, group_thresh = 0, fitness metric = log_rank, and diversity_pressure = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f299bf00",
   "metadata": {},
   "outputs": [],
   "source": [
    "# fibers = FIBERS(outcome_label=\"Duration\", outcome_type=\"survival\", iterations=100, pop_size=50, tournament_prop=0.2, pop_clean = ‘group_strata’\n",
    "#                 crossover_prob=0.5, min_mutation_prob=0.1, max_mutation_prob=0.1, merge_prob=0.0, new_gen=1.0, elitism=0.1,\n",
    "#                 diversity_pressure=0, min_bin_size=1, max_bin_size=None, max_bin_init_size=10, fitness_metric=\"log_rank\", \n",
    "#                 log_rank_weighting=None, censor_label=\"Censoring\", group_strata_min=0.2, penalty=0.5, group_thresh=0, min_thresh=0, max_thresh=3, \n",
    "#                 int_thresh=True, thresh_evolve_prob=0.5, manual_bin_init=None, covariates=None, report=None, random_seed=42, verbose=False)\n",
    "# fibers = fibers.fit(data) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "cfea13e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.skfibers.methods.data_handling import prepare_data\n",
    "def get_experiment_output(fibers, X, y=None, dataset=None, filename=None):\n",
    "        columns = [\"Features in Bin\", \"Number of P\", \"Number of R\", \n",
    "                   \"Bin Size\", \"Pred Ratio\", \"Birth Iteration\",\n",
    "                   \"Iterations to Ideal Solution\", \n",
    "                   \"Log-Rank Score\",\n",
    "                   \"Unadjusted HR\", \"HR CI\", \"HR P-value\", \"Runtime\",\n",
    "                   \"Count At/Below Threshold\",\n",
    "                   \"Count Above Threshold\", \"Group Ratio\", \n",
    "                   \"Log-Rank p-value\", \"Threshold\", \n",
    "                   \"Accuracy\",\n",
    "                   \"Residual\",\n",
    "                   \"Residual p-value\", \n",
    "                   \"Dataset Filename\"]\n",
    "        X = fibers.check_x_y(X, None)\n",
    "        X, feature_names = prepare_data(X, fibers.outcome_label, fibers.censor_label, fibers.covariates)\n",
    "        assert (feature_names == fibers.feature_names)\n",
    "\n",
    "        Bin = fibers.get_top_bins()[0]\n",
    "\n",
    "        # Sum instance values across features specified in the bin\n",
    "        feature_sums = X.loc[:, fibers.feature_names][Bin.feature_list].sum(axis=1)\n",
    "        bin_df = pd.DataFrame({'Bin':feature_sums})\n",
    "\n",
    "        bin_df['Bin'] = bin_df['Bin'].apply(lambda x: 0 if x <= Bin.group_threshold else 1)\n",
    "\n",
    "        # Create evaluation dataframe including bin sum feature, outcome, and censoring alone\n",
    "        bin_df = pd.concat([bin_df, X.loc[:, fibers.outcome_label], X.loc[:, fibers.censor_label]],axis=1)\n",
    "        try:\n",
    "            cph = CoxPHFitter()\n",
    "            cph.fit(bin_df, fibers.outcome_label,event_col=fibers.censor_label, show_progress=False)\n",
    "            summary = cph.summary\n",
    "            Bin.HR = summary['exp(coef)'].iloc[0]\n",
    "            Bin.HR_CI = str(summary['exp(coef) lower 95%'].iloc[0])+'-'+str(summary['exp(coef) upper 95%'].iloc[0])\n",
    "            Bin.HR_p_value = summary['p'].iloc[0]\n",
    "        except:\n",
    "            Bin.HR = 0\n",
    "            Bin.HR_CI = None\n",
    "            Bin.HR_p_value = None\n",
    "\n",
    "        # summary = fibers.get_cox_prop_hazard(X, 0)\n",
    "        # bin_hr = summary['exp(coef)'].iloc[0]\n",
    "        # bin_low_CI = summary['exp(coef) lower 95%'].iloc[0]\n",
    "        # bin_upper_CI = summary['exp(coef) upper 95%'].iloc[0]\n",
    "        # bin_p_val = summary['p'].iloc[0]\n",
    "        # print(\"Bin HR: \"+str(bin_hr)+\" (\"+str(bin_low_CI)+\"-\"+str(bin_upper_CI)+\")\")\n",
    "        # print(\"Bin HR p-value: \"+str(bin_p_val))\n",
    "\n",
    "        pdf = pd.DataFrame([[Bin.feature_list,\n",
    "                             str(Bin.feature_list).count('P'), str(Bin.feature_list).count('R'), \n",
    "                             Bin.bin_size, str(Bin.feature_list).count('P')/Bin.bin_size, \n",
    "                             Bin.birth_iteration,\n",
    "                             None if str(Bin.feature_list).count('P') != 10 else Bin.birth_iteration,\n",
    "                             Bin.log_rank_score, \n",
    "                             Bin.HR, Bin.HR_CI, Bin.HR_p_value, fibers.elapsed_time,\n",
    "                             Bin.count_at,\n",
    "                             Bin.count_bt, Bin.count_at/(Bin.count_at+Bin.count_bt), \n",
    "                             Bin.log_rank_p_value, Bin.group_threshold, \n",
    "                             accuracy_score(fibers.predict(X, 0), y) if y is not None else None,\n",
    "                             Bin.residuals_score, Bin.residuals_p_value, dataset]],\n",
    "                           columns=columns).T  # SPHIA\n",
    "        \n",
    "        if filename:\n",
    "            pdf.to_csv(filename)\n",
    "        return pdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "db008a26",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get_experiment_output(fibers, data, true_risk_group, dataset_name, root_folder + '/' + experiment_name\n",
    "#                                                + '/' + dataset_name.split('.')[0] + '/experiment_table.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba0cc314",
   "metadata": {},
   "source": [
    "### Accessing results and internal functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2940fa52",
   "metadata": {},
   "outputs": [],
   "source": [
    "# experiment_results = get_experiment_output(fibers, data, true_risk_group)\n",
    "# experiment_results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1245732e",
   "metadata": {},
   "source": [
    "## Code for Experiment Run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "96bc399b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_cluster(cluster_type='SLURM', output_path=\".\", queue='defq', memory=4):\n",
    "    client = None\n",
    "    try:\n",
    "        if cluster_type == 'SLURM':\n",
    "            cluster = SLURMCluster(queue=queue,\n",
    "                                   cores=1,\n",
    "                                   memory=str(memory) + \"G\",\n",
    "                                   walltime=\"24:00:00\",\n",
    "                                   log_directory=output_path + \"/dask_logs/\")\n",
    "            cluster.adapt(maximum_jobs=400)\n",
    "        elif cluster_type == \"LSF\":\n",
    "            cluster = LSFCluster(queue=queue,\n",
    "                                 cores=1,\n",
    "                                 mem=memory * 1000000000,\n",
    "                                 memory=str(memory) + \"G\",\n",
    "                                 walltime=\"24:00\",\n",
    "                                 log_directory=output_path + \"/dask_logs/\")\n",
    "            cluster.adapt(maximum_jobs=400)\n",
    "        elif cluster_type == 'UGE':\n",
    "            cluster = SGECluster(queue=queue,\n",
    "                                 cores=1,\n",
    "                                 memory=str(memory) + \"G\",\n",
    "                                 resource_spec=\"mem_free=\" + str(memory) + \"G\",\n",
    "                                 walltime=\"24:00:00\",\n",
    "                                 log_directory=output_path + \"/dask_logs/\")\n",
    "            cluster.adapt(maximum_jobs=400)\n",
    "        elif cluster_type == 'Local':\n",
    "            c = Client()\n",
    "            cluster = c.cluster\n",
    "        else:\n",
    "            raise Exception(\"Unknown or Unsupported Cluster Type\")\n",
    "        client = Client(cluster)\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "        raise Exception(\"Exception: Unknown Exception\")\n",
    "    print(\"Running dask-cluster\")\n",
    "    print(client.scheduler_info())\n",
    "    return client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a2a736ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "def runner_fn(fibers, params):\n",
    "    data, true_risk_group = read_dataset(params['dataset_name'])\n",
    "    params['data'] = data\n",
    "    params['label'] = true_risk_group\n",
    "    fibers = fibers.fit(params['data']) \n",
    "    experiment_results = get_experiment_output(fibers, params['data'], params['label'], params['dataset_name'],\n",
    "                                               params['root_folder'] + '/' + params['experiment_name'] \n",
    "                                               + '/' + params['dataset_name'].split('.')[0] \n",
    "                                               + '/models/model_table_' + str(fibers.random_seed) + '.csv')\n",
    "    with open(params['root_folder'] + '/' + params['experiment_name'] \n",
    "              + '/' + params['dataset_name'].split('.')[0] + '/models/' + str(fibers.random_seed), 'wb') as file:\n",
    "        pickle.dump(fibers, file)\n",
    "    print(params)\n",
    "    return experiment_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e4c48250",
   "metadata": {},
   "outputs": [],
   "source": [
    "fibers_list = [\n",
    "    \n",
    "    FIBERS(outcome_label=\"Duration\", outcome_type=\"survival\", iterations=100, pop_size=50, tournament_prop=0.2, pop_clean = 'group_strata',\n",
    "                    crossover_prob=0.5, min_mutation_prob=0.1, max_mutation_prob=0.1, merge_prob=0.0, new_gen=1.0, elitism=0.1,\n",
    "                    diversity_pressure=0, min_bin_size=1, max_bin_size=None, max_bin_init_size=10, fitness_metric=\"log_rank\", \n",
    "                    log_rank_weighting=None, censor_label=\"Censoring\", group_strata_min=0.2, penalty=0.5, group_thresh=0, min_thresh=0, max_thresh=5, \n",
    "                    int_thresh=True, thresh_evolve_prob=0.5, manual_bin_init=None, covariates=None, report=None, random_seed=None, verbose=False),\n",
    "    FIBERS(outcome_label=\"Duration\", outcome_type=\"survival\", iterations=100, pop_size=50, tournament_prop=0.2, pop_clean = 'group_strata',\n",
    "                    crossover_prob=0.5, min_mutation_prob=0.1, max_mutation_prob=0.1, merge_prob=0.1, new_gen=1.0, elitism=0.1,\n",
    "                    diversity_pressure=0, min_bin_size=1, max_bin_size=None, max_bin_init_size=10, fitness_metric=\"log_rank\", \n",
    "                    log_rank_weighting=None, censor_label=\"Censoring\", group_strata_min=0.2, penalty=0.5, group_thresh=0, min_thresh=0, max_thresh=5, \n",
    "                    int_thresh=True, thresh_evolve_prob=0.5, manual_bin_init=None, covariates=None, report=None, random_seed=None, verbose=False),\n",
    "    FIBERS(outcome_label=\"Duration\", outcome_type=\"survival\", iterations=100, pop_size=50, tournament_prop=0.2, pop_clean = 'group_strata',\n",
    "                    crossover_prob=0.5, min_mutation_prob=0.1, max_mutation_prob=0.5, merge_prob=0.0, new_gen=1.0, elitism=0.1,\n",
    "                    diversity_pressure=0, min_bin_size=1, max_bin_size=None, max_bin_init_size=10, fitness_metric=\"log_rank\", \n",
    "                    log_rank_weighting=None, censor_label=\"Censoring\", group_strata_min=0.2, penalty=0.5, group_thresh=0, min_thresh=0, max_thresh=5, \n",
    "                    int_thresh=True, thresh_evolve_prob=0.5, manual_bin_init=None, covariates=None, report=None, random_seed=None, verbose=False),\n",
    "    FIBERS(outcome_label=\"Duration\", outcome_type=\"survival\", iterations=100, pop_size=50, tournament_prop=0.2, pop_clean = 'group_strata',\n",
    "                    crossover_prob=0.5, min_mutation_prob=0.1, max_mutation_prob=0.5, merge_prob=0.0, new_gen=1.0, elitism=0.1,\n",
    "                    diversity_pressure=0, min_bin_size=1, max_bin_size=None, max_bin_init_size=10, fitness_metric=\"log_rank\", \n",
    "                    log_rank_weighting=None, censor_label=\"Censoring\", group_strata_min=0.2, penalty=0.5, group_thresh=None, min_thresh=0, max_thresh=5, \n",
    "                    int_thresh=True, thresh_evolve_prob=0.5, manual_bin_init=None, covariates=None, report=None, random_seed=None, verbose=False),\n",
    "    FIBERS(outcome_label=\"Duration\", outcome_type=\"survival\", iterations=100, pop_size=50, tournament_prop=0.2, pop_clean = 'group_strata',\n",
    "                    crossover_prob=0.5, min_mutation_prob=0.1, max_mutation_prob=0.5, merge_prob=0.0, new_gen=1.0, elitism=0.1,\n",
    "                    diversity_pressure=3, min_bin_size=1, max_bin_size=None, max_bin_init_size=10, fitness_metric=\"log_rank\", \n",
    "                    log_rank_weighting=None, censor_label=\"Censoring\", group_strata_min=0.2, penalty=0.5, group_thresh=None, min_thresh=0, max_thresh=5, \n",
    "                    int_thresh=True, thresh_evolve_prob=0.5, manual_bin_init=None, covariates=None, report=None, random_seed=None, verbose=False),                       \n",
    "                ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b2436719",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['standard_with_noise.csv',\n",
       " 'standard_no_noise.csv',\n",
       " 'threshold_0_no_noise.csv',\n",
       " 'threshold_0_with_noise.csv',\n",
       " 'threshold_1_no_noise.csv',\n",
       " 'threshold_1_with_noise.csv',\n",
       " 'threshold_2_no_noise.csv',\n",
       " 'threshold_2_with_noise.csv',\n",
       " 'threshold_4_no_noise.csv',\n",
       " 'threshold_4_with_noise.csv']"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_name_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "d096dadf",
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = [\n",
    "        (\"Goal1\", dataset_name_list[0], fibers_list[0]),\n",
    "        (\"Goal1\", dataset_name_list[1], fibers_list[0]), \n",
    "        (\"Goal2\", dataset_name_list[0], fibers_list[1]), \n",
    "        (\"Goal2\", dataset_name_list[1], fibers_list[1]), \n",
    "        (\"Goal3\", dataset_name_list[0], fibers_list[2]), \n",
    "        (\"Goal3\", dataset_name_list[1], fibers_list[2]), \n",
    "        (\"Goal4\", dataset_name_list[2], fibers_list[3]), \n",
    "        (\"Goal4\", dataset_name_list[3], fibers_list[3]), \n",
    "        (\"Goal4\", dataset_name_list[4], fibers_list[3]), \n",
    "        (\"Goal4\", dataset_name_list[5], fibers_list[3]), \n",
    "        (\"Goal4\", dataset_name_list[6], fibers_list[3]), \n",
    "        (\"Goal4\", dataset_name_list[7], fibers_list[3]), \n",
    "        (\"Goal4\", dataset_name_list[8], fibers_list[3]), \n",
    "        (\"Goal4\", dataset_name_list[9], fibers_list[3]), \n",
    "        (\"Goal5\", dataset_name_list[4], fibers_list[4]), \n",
    "        (\"Goal5\", dataset_name_list[5], fibers_list[4]), \n",
    "    ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "005a226b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Folder Already Exists:PPSNResults/FIBERS2//Goal1/standard_with_noise/\n",
      "Folder Already Exists:PPSNResults/FIBERS2//Goal1/standard_no_noise/\n",
      "Folder Already Exists:PPSNResults/FIBERS2//Goal2/standard_with_noise/\n",
      "Folder Already Exists:PPSNResults/FIBERS2//Goal2/standard_no_noise/\n",
      "Folder Already Exists:PPSNResults/FIBERS2//Goal3/standard_with_noise/\n",
      "Folder Already Exists:PPSNResults/FIBERS2//Goal3/standard_no_noise/\n",
      "Folder Already Exists:PPSNResults/FIBERS2//Goal4/threshold_0_no_noise/\n",
      "Folder Already Exists:PPSNResults/FIBERS2//Goal4/threshold_0_with_noise/\n",
      "Folder Already Exists:PPSNResults/FIBERS2//Goal4/threshold_1_no_noise/\n",
      "Folder Already Exists:PPSNResults/FIBERS2//Goal4/threshold_1_with_noise/\n",
      "Folder Already Exists:PPSNResults/FIBERS2//Goal4/threshold_2_no_noise/\n",
      "Folder Already Exists:PPSNResults/FIBERS2//Goal4/threshold_2_with_noise/\n",
      "Folder Already Exists:PPSNResults/FIBERS2//Goal4/threshold_4_no_noise/\n",
      "Folder Already Exists:PPSNResults/FIBERS2//Goal4/threshold_4_with_noise/\n",
      "Folder Already Exists:PPSNResults/FIBERS2//Goal5/threshold_1_no_noise/\n",
      "Folder Already Exists:PPSNResults/FIBERS2//Goal5/threshold_1_with_noise/\n"
     ]
    }
   ],
   "source": [
    "# for experiment_name in experiment_list:\n",
    "#     for dataset_name in dataset_name_list:\n",
    "DEBUG = False\n",
    "if DEBUG:\n",
    "    import shutil\n",
    "    try:\n",
    "        shutil.rmtree(root_folder)\n",
    "    except:\n",
    "        pass\n",
    "for experiment_name, dataset_name, _ in param_grid:\n",
    "    try:\n",
    "        folder = root_folder + '/' + experiment_name + '/' + dataset_name.split('.')[0] + '/'\n",
    "        os.makedirs(folder + '/models/')\n",
    "    except FileExistsError:\n",
    "        folder = root_folder + '/' + experiment_name + '/' + dataset_name.split('.')[0] + '/'\n",
    "        print(\"Folder Already Exists:\" + folder)\n",
    "\n",
    "        continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "097407e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_obj_list(fibers, param):  \n",
    "    obj_list = list()\n",
    "    permutations = 20\n",
    "    if DEBUG:\n",
    "        permutations = 2\n",
    "    for i in range(permutations):\n",
    "        fibers.random_seed = i+1\n",
    "        obj_list.append((copy.deepcopy(fibers), param))\n",
    "    return obj_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "9fa3cd07",
   "metadata": {},
   "outputs": [],
   "source": [
    "def param_maker(dataset_name, experiment_name):\n",
    "    param_dict = {\n",
    "        'root_folder': root_folder,\n",
    "        'dataset_name': dataset_name,\n",
    "        'experiment_name': experiment_name,\n",
    "    }\n",
    "    return param_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "b84fdd53",
   "metadata": {},
   "outputs": [],
   "source": [
    "job_list = list()\n",
    "for experiment_name, dataset_name, fibers in param_grid: \n",
    "    job_list.extend(make_obj_list(fibers, param_maker(dataset_name, experiment_name)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "4c2b59ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running dask-cluster\n",
      "{'type': 'Scheduler', 'id': 'Scheduler-b5e593a9-fb65-446d-8d16-4ecc80412974', 'address': 'tcp://10.17.134.112:36363', 'services': {'dashboard': 45625}, 'started': 1713417188.9243107, 'workers': {}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/bandheyh/common/anaconda3/envs/fibers/lib/python3.8/site-packages/distributed/node.py:182: UserWarning: Port 8787 is already in use.\n",
      "Perhaps you already have a cluster running?\n",
      "Hosting the HTTP server on port 45625 instead\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "client = get_cluster('SLURM')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "fd711ab0",
   "metadata": {},
   "outputs": [],
   "source": [
    "results = dask.compute([dask.delayed(runner_fn)(fibers_obj, params\n",
    "                                            ) for fibers_obj, params in job_list])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "01bb8048",
   "metadata": {},
   "outputs": [],
   "source": [
    "result_df = pd.concat(results[0], axis=1, ignore_index=False).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "69db677c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Features in Bin</th>\n",
       "      <th>Number of P</th>\n",
       "      <th>Number of R</th>\n",
       "      <th>Bin Size</th>\n",
       "      <th>Pred Ratio</th>\n",
       "      <th>Birth Iteration</th>\n",
       "      <th>Iterations to Ideal Solution</th>\n",
       "      <th>Log-Rank Score</th>\n",
       "      <th>Unadjusted HR</th>\n",
       "      <th>HR CI</th>\n",
       "      <th>...</th>\n",
       "      <th>Runtime</th>\n",
       "      <th>Count At/Below Threshold</th>\n",
       "      <th>Count Above Threshold</th>\n",
       "      <th>Group Ratio</th>\n",
       "      <th>Log-Rank p-value</th>\n",
       "      <th>Threshold</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Residual</th>\n",
       "      <th>Residual p-value</th>\n",
       "      <th>Dataset Filename</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[P_1, P_10, P_3, P_4, P_5, P_7, P_8]</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>1.0</td>\n",
       "      <td>29</td>\n",
       "      <td>None</td>\n",
       "      <td>1555.118393</td>\n",
       "      <td>2.413567</td>\n",
       "      <td>2.3073349398995586-2.5246904024552883</td>\n",
       "      <td>...</td>\n",
       "      <td>172.681008</td>\n",
       "      <td>4928</td>\n",
       "      <td>5072</td>\n",
       "      <td>0.4928</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.9928</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>standard_with_noise.csv</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[P_1, P_10, P_3, P_4, P_5, P_7, P_8]</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>1.0</td>\n",
       "      <td>13</td>\n",
       "      <td>None</td>\n",
       "      <td>1555.118393</td>\n",
       "      <td>2.413567</td>\n",
       "      <td>2.3073349398995586-2.5246904024552883</td>\n",
       "      <td>...</td>\n",
       "      <td>184.160742</td>\n",
       "      <td>4928</td>\n",
       "      <td>5072</td>\n",
       "      <td>0.4928</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.9928</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>standard_with_noise.csv</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[P_1, P_10, P_3, P_4, P_5, P_7, P_8]</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>1.0</td>\n",
       "      <td>30</td>\n",
       "      <td>None</td>\n",
       "      <td>1555.118393</td>\n",
       "      <td>2.413567</td>\n",
       "      <td>2.3073349398995586-2.5246904024552883</td>\n",
       "      <td>...</td>\n",
       "      <td>186.027752</td>\n",
       "      <td>4928</td>\n",
       "      <td>5072</td>\n",
       "      <td>0.4928</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.9928</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>standard_with_noise.csv</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[P_1, P_10, P_3, P_4, P_5, P_8, P_7]</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>1.0</td>\n",
       "      <td>19</td>\n",
       "      <td>None</td>\n",
       "      <td>1555.118393</td>\n",
       "      <td>2.413567</td>\n",
       "      <td>2.3073349398995586-2.5246904024552883</td>\n",
       "      <td>...</td>\n",
       "      <td>162.984207</td>\n",
       "      <td>4928</td>\n",
       "      <td>5072</td>\n",
       "      <td>0.4928</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.9928</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>standard_with_noise.csv</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[P_1, P_10, P_3, P_4, P_5, P_7, P_8]</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>1.0</td>\n",
       "      <td>21</td>\n",
       "      <td>None</td>\n",
       "      <td>1555.118393</td>\n",
       "      <td>2.413567</td>\n",
       "      <td>2.3073349398995586-2.5246904024552883</td>\n",
       "      <td>...</td>\n",
       "      <td>167.338677</td>\n",
       "      <td>4928</td>\n",
       "      <td>5072</td>\n",
       "      <td>0.4928</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.9928</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>standard_with_noise.csv</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[P_1, P_2, P_3, P_4, P_5, P_6, P_7, P_8, P_9]</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>1.0</td>\n",
       "      <td>80</td>\n",
       "      <td>None</td>\n",
       "      <td>1676.757094</td>\n",
       "      <td>2.505191</td>\n",
       "      <td>2.3943569808923995-2.62115471804492</td>\n",
       "      <td>...</td>\n",
       "      <td>193.227539</td>\n",
       "      <td>4927</td>\n",
       "      <td>5073</td>\n",
       "      <td>0.4927</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.9927</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>threshold_1_with_noise.csv</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[P_1, P_10, P_2, P_3, P_4, P_5, P_6, P_7, P_9,...</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>1.0</td>\n",
       "      <td>41</td>\n",
       "      <td>41</td>\n",
       "      <td>1702.099677</td>\n",
       "      <td>2.522881</td>\n",
       "      <td>2.4112109166731734-2.6397221807476394</td>\n",
       "      <td>...</td>\n",
       "      <td>186.783333</td>\n",
       "      <td>5000</td>\n",
       "      <td>5000</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>threshold_1_with_noise.csv</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[P_1, P_2, P_3, P_4, P_5, P_6, P_7, P_8, P_9]</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>1.0</td>\n",
       "      <td>75</td>\n",
       "      <td>None</td>\n",
       "      <td>1676.757094</td>\n",
       "      <td>2.505191</td>\n",
       "      <td>2.3943569808923995-2.62115471804492</td>\n",
       "      <td>...</td>\n",
       "      <td>199.781475</td>\n",
       "      <td>4927</td>\n",
       "      <td>5073</td>\n",
       "      <td>0.4927</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.9927</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>threshold_1_with_noise.csv</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[P_1, P_2, P_3, P_4, P_5, P_6, P_7, P_9]</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>1.0</td>\n",
       "      <td>35</td>\n",
       "      <td>None</td>\n",
       "      <td>1650.787898</td>\n",
       "      <td>2.487886</td>\n",
       "      <td>2.377830522149448-2.603035047344659</td>\n",
       "      <td>...</td>\n",
       "      <td>199.346936</td>\n",
       "      <td>4821</td>\n",
       "      <td>5179</td>\n",
       "      <td>0.4821</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.9821</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>threshold_1_with_noise.csv</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[P_1, P_10, P_2, P_3, P_4, P_5, P_6, P_7, P_8,...</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>1.0</td>\n",
       "      <td>73</td>\n",
       "      <td>73</td>\n",
       "      <td>1702.099677</td>\n",
       "      <td>2.522881</td>\n",
       "      <td>2.4112109166731734-2.6397221807476394</td>\n",
       "      <td>...</td>\n",
       "      <td>180.352948</td>\n",
       "      <td>5000</td>\n",
       "      <td>5000</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>threshold_1_with_noise.csv</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>320 rows × 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                      Features in Bin Number of P Number of R  \\\n",
       "0                [P_1, P_10, P_3, P_4, P_5, P_7, P_8]           7           0   \n",
       "0                [P_1, P_10, P_3, P_4, P_5, P_7, P_8]           7           0   \n",
       "0                [P_1, P_10, P_3, P_4, P_5, P_7, P_8]           7           0   \n",
       "0                [P_1, P_10, P_3, P_4, P_5, P_8, P_7]           7           0   \n",
       "0                [P_1, P_10, P_3, P_4, P_5, P_7, P_8]           7           0   \n",
       "..                                                ...         ...         ...   \n",
       "0       [P_1, P_2, P_3, P_4, P_5, P_6, P_7, P_8, P_9]           9           0   \n",
       "0   [P_1, P_10, P_2, P_3, P_4, P_5, P_6, P_7, P_9,...          10           0   \n",
       "0       [P_1, P_2, P_3, P_4, P_5, P_6, P_7, P_8, P_9]           9           0   \n",
       "0            [P_1, P_2, P_3, P_4, P_5, P_6, P_7, P_9]           8           0   \n",
       "0   [P_1, P_10, P_2, P_3, P_4, P_5, P_6, P_7, P_8,...          10           0   \n",
       "\n",
       "   Bin Size Pred Ratio Birth Iteration Iterations to Ideal Solution  \\\n",
       "0         7        1.0              29                         None   \n",
       "0         7        1.0              13                         None   \n",
       "0         7        1.0              30                         None   \n",
       "0         7        1.0              19                         None   \n",
       "0         7        1.0              21                         None   \n",
       "..      ...        ...             ...                          ...   \n",
       "0         9        1.0              80                         None   \n",
       "0        10        1.0              41                           41   \n",
       "0         9        1.0              75                         None   \n",
       "0         8        1.0              35                         None   \n",
       "0        10        1.0              73                           73   \n",
       "\n",
       "   Log-Rank Score Unadjusted HR                                  HR CI  ...  \\\n",
       "0     1555.118393      2.413567  2.3073349398995586-2.5246904024552883  ...   \n",
       "0     1555.118393      2.413567  2.3073349398995586-2.5246904024552883  ...   \n",
       "0     1555.118393      2.413567  2.3073349398995586-2.5246904024552883  ...   \n",
       "0     1555.118393      2.413567  2.3073349398995586-2.5246904024552883  ...   \n",
       "0     1555.118393      2.413567  2.3073349398995586-2.5246904024552883  ...   \n",
       "..            ...           ...                                    ...  ...   \n",
       "0     1676.757094      2.505191    2.3943569808923995-2.62115471804492  ...   \n",
       "0     1702.099677      2.522881  2.4112109166731734-2.6397221807476394  ...   \n",
       "0     1676.757094      2.505191    2.3943569808923995-2.62115471804492  ...   \n",
       "0     1650.787898      2.487886    2.377830522149448-2.603035047344659  ...   \n",
       "0     1702.099677      2.522881  2.4112109166731734-2.6397221807476394  ...   \n",
       "\n",
       "       Runtime Count At/Below Threshold Count Above Threshold Group Ratio  \\\n",
       "0   172.681008                     4928                  5072      0.4928   \n",
       "0   184.160742                     4928                  5072      0.4928   \n",
       "0   186.027752                     4928                  5072      0.4928   \n",
       "0   162.984207                     4928                  5072      0.4928   \n",
       "0   167.338677                     4928                  5072      0.4928   \n",
       "..         ...                      ...                   ...         ...   \n",
       "0   193.227539                     4927                  5073      0.4927   \n",
       "0   186.783333                     5000                  5000         0.5   \n",
       "0   199.781475                     4927                  5073      0.4927   \n",
       "0   199.346936                     4821                  5179      0.4821   \n",
       "0   180.352948                     5000                  5000         0.5   \n",
       "\n",
       "   Log-Rank p-value Threshold Accuracy Residual Residual p-value  \\\n",
       "0               0.0         0   0.9928     None             None   \n",
       "0               0.0         0   0.9928     None             None   \n",
       "0               0.0         0   0.9928     None             None   \n",
       "0               0.0         0   0.9928     None             None   \n",
       "0               0.0         0   0.9928     None             None   \n",
       "..              ...       ...      ...      ...              ...   \n",
       "0               0.0         1   0.9927     None             None   \n",
       "0               0.0         1      1.0     None             None   \n",
       "0               0.0         1   0.9927     None             None   \n",
       "0               0.0         1   0.9821     None             None   \n",
       "0               0.0         1      1.0     None             None   \n",
       "\n",
       "              Dataset Filename  \n",
       "0      standard_with_noise.csv  \n",
       "0      standard_with_noise.csv  \n",
       "0      standard_with_noise.csv  \n",
       "0      standard_with_noise.csv  \n",
       "0      standard_with_noise.csv  \n",
       "..                         ...  \n",
       "0   threshold_1_with_noise.csv  \n",
       "0   threshold_1_with_noise.csv  \n",
       "0   threshold_1_with_noise.csv  \n",
       "0   threshold_1_with_noise.csv  \n",
       "0   threshold_1_with_noise.csv  \n",
       "\n",
       "[320 rows x 21 columns]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed33fca2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
